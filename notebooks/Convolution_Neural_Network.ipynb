{"metadata": {"language_info": {"codemirror_mode": {"name": "ipython", "version": 2}, "file_extension": ".py", "pygments_lexer": "ipython2", "name": "python", "mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "2.7.11"}, "kernelspec": {"display_name": "Python 2 with Spark 2.0", "name": "python2-spark20", "language": "python"}}, "nbformat_minor": 0, "cells": [{"metadata": {"collapsed": true}, "source": "# Keras Code for training CNN on the SETI signal images\n    1. Get the input data in the format of Numpy ndarrays in greyscale. Split the data into training and testing set. Probably 0.9:0.1\n    2. We need to decide on the design parameters of the network\n    3. Train the classifier\n    4. Test the classifier", "cell_type": "markdown"}, {"outputs": [{"name": "stderr", "output_type": "stream", "text": "Using TensorFlow backend.\n"}], "metadata": {"collapsed": false}, "source": "import os\nimport zipfile\nimport ibmseti\nimport keras\nimport numpy as np\nfrom keras.datasets import cifar10\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.constraints import maxnorm\nfrom keras.optimizers import SGD\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.utils import np_utils\nfrom keras import backend as K\nK.set_image_dim_ordering('th')", "cell_type": "code", "execution_count": 1}, {"outputs": [], "metadata": {"collapsed": true}, "source": "mydatafolder = os.path.join(os.environ['PWD'],'Machine_Contact_Enterprise_SETI')\nzz = zipfile.ZipFile(mydatafolder + '/' + 'basic4.zip')\nbasic4list = zz.namelist()[1:]", "cell_type": "code", "execution_count": 2}, {"outputs": [], "metadata": {"collapsed": true}, "source": "def get_spectral_ndarray(filename):\n    img = ibmseti.compamp.SimCompamp(zz.open(filename).read())\n    return (img.get_spectrogram(),img.header()[\"signal_classification\"])", "cell_type": "code", "execution_count": 3}, {"outputs": [], "metadata": {"collapsed": false}, "source": "def load_training_data():\n    x_list = []\n    y_list = []\n    for filename in basic4list[0:10]:\n        ans = get_spectral_ndarray(filename)\n        x_list.append(ans[0])\n        y_list.append(ans[1])\n    return (np.array(x_list),np.array(y_list))", "cell_type": "code", "execution_count": 4}, {"outputs": [], "metadata": {"collapsed": false}, "source": "seed = 7\nnp.random.seed(seed)", "cell_type": "code", "execution_count": 5}, {"outputs": [], "metadata": {"collapsed": false}, "source": "# load training data\n(X_train, y_train) = load_training_data()\n#(X_test, y_test) = load_test_data()", "cell_type": "code", "execution_count": 6}, {"outputs": [{"name": "stdout", "output_type": "stream", "text": "[1 3 2 3 0 2 0 3 3 0]\n"}], "metadata": {"collapsed": false}, "source": "# one-hot encoding\nfrom sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nprint np.array(le.fit_transform(y_train))\ny_train = np_utils.to_categorical(np.array(le.fit_transform(y_train)))", "cell_type": "code", "execution_count": 7}, {"outputs": [{"name": "stdout", "output_type": "stream", "text": "[[ 0.  1.  0.  0.]\n [ 0.  0.  0.  1.]\n [ 0.  0.  1.  0.]\n [ 0.  0.  0.  1.]\n [ 1.  0.  0.  0.]\n [ 0.  0.  1.  0.]\n [ 1.  0.  0.  0.]\n [ 0.  0.  0.  1.]\n [ 0.  0.  0.  1.]\n [ 1.  0.  0.  0.]]\n"}], "metadata": {"collapsed": false}, "source": "print y_train\n#for i in range(len(y_train)):\n#    if y_train[i] == 'narrowbanddrd'", "cell_type": "code", "execution_count": 8}, {"outputs": [], "metadata": {"collapsed": true}, "source": "# normalize the data\nX_train = X_train.astype('float32')\nX_train = X_train / 255.0", "cell_type": "code", "execution_count": null}, {"outputs": [], "metadata": {"collapsed": true}, "source": "# clean noise from the data\nX.shape\naverage_noise=np.zeros(noise[0].shape)\nfor n in noise:\n    average_noise += n/1000\n", "cell_type": "code", "execution_count": null}, {"outputs": [], "metadata": {"collapsed": true}, "source": "firstfile = basic4list[0]\naca = ibmseti.compamp.SimCompamp(zz.open(firstfile).read())\naca.header() # this shows the classification\nspectrogram = aca.get_spectrogram()\nspectrogram = spectrogram - noise - np.mean(spectrogram)\nfig, ax = plt.subplots(figsize=(10, 5))\nax.imshow(np.log(spectrogram),  aspect = 0.5*float(spectrogram.shape[1]) / spectrogram.shape[0])", "cell_type": "code", "execution_count": null}, {"outputs": [{"name": "stdout", "output_type": "stream", "text": "basic4_test.zip\t\t\t\t  public_list_basic_v2_26may_2017.csv\r\nbasic4.zip\t\t\t\t  watson_results.pickle\r\ncleanPngs\t\t\t\t  watson_scores.csv\r\ndata\t\t\t\t\t  zipfiles\r\npublic_list_basic_testset_1june_2017.csv\r\n"}], "metadata": {"collapsed": false}, "source": "!ls Machine_Contact_Enterprise_SETI/", "cell_type": "code", "execution_count": 10}, {"outputs": [{"traceback": ["\u001b[0;31m\u001b[0m", "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)", "\u001b[0;32m<ipython-input-29-610d4c73cb9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6144\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m/usr/local/src/bluemix_jupyter_bundle.v46/notebook/lib/python2.7/site-packages/keras/models.pyc\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    282\u001b[0m             raise TypeError('The added layer must be '\n\u001b[1;32m    283\u001b[0m                             \u001b[0;34m'an instance of class Layer. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m                             'Found: ' + str(layer))\n\u001b[0m\u001b[1;32m    285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0;31m# first layer in model: check that it is an input layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mTypeError\u001b[0m: The added layer must be an instance of class Layer. Found: Tensor(\"input_2:0\", shape=(?, 1, 32, 6144), dtype=float32)"], "output_type": "error", "evalue": "The added layer must be an instance of class Layer. Found: Tensor(\"input_2:0\", shape=(?, 1, 32, 6144), dtype=float32)", "ename": "TypeError"}], "metadata": {"collapsed": false}, "source": "# define CNN model\nfrom keras.layers import Input\nmodel = Sequential()\nmodel.add(Input(shape=(1, 32, 6144)))\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Dropout(0.2))\nmodel.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Flatten())\nmodel.add(Dense(50, activation='relu', kernel_constraint=maxnorm(3)))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))", "cell_type": "code", "execution_count": 29}, {"outputs": [{"data": {"text/plain": "(32, 6144)"}, "metadata": {}, "output_type": "execute_result", "execution_count": 13}], "metadata": {"collapsed": false}, "source": "epochs = 25\nlrate = 0.01\ndecay = lrate/epochs\nsgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\nmodel.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\nprint(model.summary())", "cell_type": "code", "execution_count": 13}, {"outputs": [], "metadata": {"collapsed": true}, "source": "model.fit(X_train, y_train, validation_split=0.1 epochs=epochs, batch_size=150)\n# Final evaluation of the model\nscores = model.evaluate(X_test, y_test, verbose=0)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))", "cell_type": "code", "execution_count": null}, {"outputs": [{"name": "stdout", "output_type": "stream", "text": "Collecting keras\n  Downloading Keras-2.0.4.tar.gz (199kB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 204kB 3.8MB/s \n\u001b[?25hCollecting theano (from keras)\n  Downloading Theano-0.9.0.tar.gz (3.1MB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3.1MB 353kB/s \n\u001b[?25hCollecting pyyaml (from keras)\n  Downloading PyYAML-3.12.tar.gz (253kB)\n\u001b[K    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 256kB 3.2MB/s \n\u001b[?25hRequirement already up-to-date: six in /usr/local/src/bluemix_jupyter_bundle.v46/notebook/lib/python2.7/site-packages (from keras)\nRequirement already up-to-date: numpy>=1.9.1 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s18f-42b3305d048694-5fca760d00b1/.local/lib/python2.7/site-packages (from theano->keras)\nRequirement already up-to-date: scipy>=0.14 in /gpfs/global_fs01/sym_shared/YPProdSpark/user/s18f-42b3305d048694-5fca760d00b1/.local/lib/python2.7/site-packages (from theano->keras)\nBuilding wheels for collected packages: keras, theano, pyyaml\n  Running setup.py bdist_wheel for keras ... \u001b[?25l-\b \b\\\b \bdone\n\u001b[?25h  Stored in directory: /gpfs/fs01/user/s18f-42b3305d048694-5fca760d00b1/.cache/pip/wheels/48/82/42/f06a8c03a8f95ada523a81ba723e89f059693e6ad868d09727\n  Running setup.py bdist_wheel for theano ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \bdone\n\u001b[?25h  Stored in directory: /gpfs/fs01/user/s18f-42b3305d048694-5fca760d00b1/.cache/pip/wheels/d5/5b/93/433299b86e3e9b25f0f600e4e4ebf18e38eb7534ea518eba13\n  Running setup.py bdist_wheel for pyyaml ... \u001b[?25l-\b \bdone\n\u001b[?25h  Stored in directory: /gpfs/fs01/user/s18f-42b3305d048694-5fca760d00b1/.cache/pip/wheels/2c/f7/79/13f3a12cd723892437c0cfbde1230ab4d82947ff7b3839a4fc\nSuccessfully built keras theano pyyaml\nInstalling collected packages: theano, pyyaml, keras\nSuccessfully installed keras-2.0.4 pyyaml-3.12 theano-0.9.0\n"}], "metadata": {"collapsed": false}, "source": "!pip install --upgrade keras", "cell_type": "code", "execution_count": 19}, {"outputs": [], "metadata": {"collapsed": true}, "source": "", "cell_type": "code", "execution_count": null}], "nbformat": 4}
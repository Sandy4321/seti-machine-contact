{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### SET YOUR TEAM NAME HERE! Use this folder to save intermediate results\n",
    "teamname = 'Machine_Contact_Enterprise_SETI'\n",
    "mydatafolder = os.path.join( os.environ['PWD'], teamname )      \n",
    "input_png_folder = mydatafolder + '/cleanPngsTest'\n",
    "output_zip_folder = mydatafolder + '/zippedPngsTestDay99'\n",
    "workingIndexFile = os.path.join( mydatafolder + '/public_list_basic_v2_26may_2017.csv' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#open(workingIndexFile).read().split(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Create Training / Test sets\n",
    "\n",
    "Using the `basic` list, we'll create training and test sets for each signal class. Then we'll archive the `.png` files into a handful of `.zip` files (We need the .zip files to be smaller than 25 MB each because there is a limitation with the size of batches of data that are uploaded to Watson Visual Recognition when training a classifier (200 MB total).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 4000 files\n"
     ]
    }
   ],
   "source": [
    "# Grab the Basic file list in order to \n",
    "# Organize the Data into classes if it is a training set\n",
    "\n",
    "indexfile_rows = open(workingIndexFile).readlines()\n",
    "                                                    \n",
    "uuids_classes_as_list = indexfile_rows  [1:]#slice off the first line (header)\n",
    "\n",
    "def row_to_json(row):\n",
    "    uuid,sigclass = row.strip('\\n').split(',')  #strip \\n and split uuid, class\n",
    "    return {'uuid':uuid, 'signal_classification':sigclass}\n",
    "\n",
    "uuids_classes_as_list = map(lambda row: row_to_json(row), uuids_classes_as_list)\n",
    "print \"found {} files\".format(len(uuids_classes_as_list))\n",
    "\n",
    "uuids_group_by_class = {}\n",
    "for item in uuids_classes_as_list:\n",
    "    uuids_group_by_class.setdefault(item['signal_classification'], []).append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "squiggle: training set size: 900\n",
      "squiggle: test set size: 100\n",
      "narrowband: training set size: 900\n",
      "narrowband: test set size: 100\n",
      "noise: training set size: 900\n",
      "noise: test set size: 100\n",
      "narrowbanddrd: training set size: 900\n",
      "narrowbanddrd: test set size: 100\n"
     ]
    }
   ],
   "source": [
    "#At first, use just 20 percent and 10 percent. This will be useful \n",
    "#as you prototype. You'll you use these to train Watson in the next notebook\n",
    "#So, if we only do the first 20 percent and 10 percent, we can move through\n",
    "#the tutorial quickly at first. Then you can come back here and increase these\n",
    "#percentages.\n",
    "training_percentage = 0.9\n",
    "test_percentage = 0.1\n",
    "\n",
    "assert training_percentage + test_percentage <= 1.0\n",
    "\n",
    "training_set_group_by_class = {}\n",
    "test_set_group_by_class = {}\n",
    "for k, v in uuids_group_by_class.iteritems():\n",
    "    \n",
    "    total = len(v)\n",
    "    training_size = int(total * training_percentage)\n",
    "    test_size = int(total * test_percentage)\n",
    "    \n",
    "    training_set = v[:training_size]\n",
    "    test_set = v[-1*test_size:]\n",
    "    \n",
    "    training_set_group_by_class[k] = training_set\n",
    "    test_set_group_by_class[k] = test_set\n",
    "    \n",
    "    print '{}: training set size: {}'.format(k, len(training_set))\n",
    "    print '{}: test set size: {}'.format(k, len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'signal_classification': 'noise',\n",
       " 'uuid': '498becc2-3693-45b3-8533-50e93532706a'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set_group_by_class['noise'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "if os.path.exists(output_zip_folder) is False:\n",
    "    os.makedirs(output_zip_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_zip_file_size_in_mb = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 2] No such file or directory: '/gpfs/fs01/user/s18f-42b3305d048694-5fca760d00b1/notebook/work/Machine_Contact_Enterprise_SETI/cleanPngsTest/99b5c77b-62ac-4927-8bcb-9086df2d60bf.dat.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mOSError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-5d4e87a761fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mzz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mzz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/src/bluemix_jupyter_bundle.v46/notebook/lib/python2.7/zipfile.pyc\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, filename, arcname, compress_type)\u001b[0m\n\u001b[1;32m   1121\u001b[0m                   \"Attempt to write to ZIP archive that was already closed\")\n\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1123\u001b[0;31m         \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1124\u001b[0m         \u001b[0misdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mS_ISDIR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m         \u001b[0mmtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocaltime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mst_mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 2] No such file or directory: '/gpfs/fs01/user/s18f-42b3305d048694-5fca760d00b1/notebook/work/Machine_Contact_Enterprise_SETI/cleanPngsTest/99b5c77b-62ac-4927-8bcb-9086df2d60bf.dat.png'"
     ]
    }
   ],
   "source": [
    "#Create the Zip files containing the training PNG files\n",
    "#Note that this limits output files to be less than <max_zip_file_size_in_mb> MB because WatsonVR has a limit on the \n",
    "#size of input files that can be sent in single HTTP calls to train a custom classifier\n",
    "for k, v, in training_set_group_by_class.iteritems():\n",
    "    fnames = [ os.path.join(input_png_folder, vv['uuid'] + '.dat.png') for vv in v]\n",
    "    count = 1\n",
    "    for fn in fnames:\n",
    "\n",
    "        archive_name = '{}/classification_{}_{}.zip'.format(output_zip_folder, count, k)\n",
    "\n",
    "        if os.path.exists(archive_name):\n",
    "            zz = zipfile.ZipFile(archive_name, mode='a')\n",
    "        else:\n",
    "            print 'creating new archive', archive_name\n",
    "            zz = zipfile.ZipFile(archive_name, mode='w')\n",
    "\n",
    "\n",
    "        zz.write(fn, fn.split('/')[-1])\n",
    "        zz.close()\n",
    "\n",
    "        #if archive_name folder exceeds <max_zip_file_size_in_mb> MB, increase count to create a new one\n",
    "        if os.path.getsize(archive_name) > max_zip_file_size_in_mb * 1024 ** 2:\n",
    "            count += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create the Zip files containing the test PNG files using the following naming convention:\n",
    "# testset_<NUMBER>_<CLASS>.zip (step 4 will break if a different naming convention is used)\n",
    "# Refer to https://www.ibm.com/watson/developercloud/visual-recognition/api/v3/#classify_an_image for ZIP size and content limitations:\n",
    "# \"The max number of images in a .zip file is limited to 20, and limited to 5 MB.\"\n",
    "for k, v, in test_set_group_by_class.iteritems():\n",
    "\n",
    "    fnames = [outputpng_folder + '/' + vv['uuid'] + '.dat.png' for vv in v]\n",
    "\n",
    "    # archive counter\n",
    "    count = 1\n",
    "    # number of image files in archive counter\n",
    "    image_count = 0\n",
    "    for fn in fnames:\n",
    "\n",
    "        archive_name = '{}/testset_{}_{}.zip'.format(zipfilefolder, count, k)\n",
    "\n",
    "        if os.path.exists(archive_name):\n",
    "            if os.path.getsize(archive_name) + os.path.getsize(fn) >= 4.8 * 1024 ** 2:\n",
    "                # current ZIP archive size + size of this file > max size (or at least close to); create new archive\n",
    "                count += 1\n",
    "                image_count = 0\n",
    "                archive_name = '{}/testset_{}_{}.zip'.format(zipfilefolder, count, k)\n",
    "                print 'creating new archive', archive_name\n",
    "                zz = zipfile.ZipFile(archive_name, mode='w')\n",
    "            else:\n",
    "                zz = zipfile.ZipFile(archive_name, mode='a')\n",
    "        else:\n",
    "            print 'creating new archive', archive_name\n",
    "            zz = zipfile.ZipFile(archive_name, mode='w')\n",
    "\n",
    "        zz.write(fn)\n",
    "        zz.close()\n",
    "\n",
    "        image_count += 1\n",
    "        # the number of files > max number of files supported by API; create new archive\n",
    "        if image_count > 19:\n",
    "            count +=1\n",
    "            image_count = 0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 with Spark 1.6",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
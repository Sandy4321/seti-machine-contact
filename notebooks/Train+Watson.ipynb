{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Watson Visual Recognition Training with Spectrogram Images from SETI Signal Data\n",
    "\n",
    "* https://www.ibm.com/watson/developercloud/visual-recognition/api/v3/\n",
    "* https://www.ibm.com/watson/developercloud/doc/visual-recognition/customizing.html\n",
    "* https://github.com/watson-developer-cloud/python-sdk\n",
    "* https://github.com/watson-developer-cloud/python-sdk/blob/master/watson_developer_cloud/visual_recognition_v3.py\n",
    "\n",
    "<hr>\n",
    "\n",
    "## Install the Watson Developer Cloud Python SDK\n",
    "\n",
    "* Install the Python SDK if has not been previously installed\n",
    "* Restart the kernel, after installing the SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#!pip install --user --upgrade watson-developer-cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "\n",
    "import glob\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "import timeit\n",
    "import zipfile\n",
    "\n",
    "from random import randint\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "teamname = \"Machine_Contact_Enterprise_SETI\"\n",
    "zipfilefolder = os.path.join( os.environ['PWD'], teamname ) + '/zippedPngsTestDay1'\n",
    "\n",
    "\n",
    "mydatafolder = os.path.join( os.environ['PWD'], teamname )  \n",
    "if os.path.exists(mydatafolder) is False:\n",
    "    raise Exception('The data folder does not exist')\n",
    "\n",
    "if os.path.exists(zipfilefolder) is False:\n",
    "    raise Exception('The zip folder does not exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from watson_developer_cloud import VisualRecognitionV3\n",
    "apiVer = VisualRecognitionV3.latest_version #'2016-05-20'\n",
    "classifier_prefix = teamname + \"_v1_\"\n",
    "\n",
    "#You can sign up with WatsonVR through Bluemix to get a key\n",
    "#However, Hackathon participants will be provided with a WATSON VR key that has more free API calls per day.\n",
    "apiKey = 'c70486e04c0e6ac12314da71f2fdb88992420c33'  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "vr = VisualRecognitionV3(apiVer, api_key=apiKey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<br/>\n",
    "## Look For Existing Custom Classifier\n",
    "Use an existing custom classifier (and update) if one exists, else a new custom classifier will be created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "classifier_id = None\n",
    "classifier = None\n",
    "\n",
    "classifiers = vr.list_classifiers()\n",
    "\n",
    "for c in classifiers['classifiers']:\n",
    "    if c['status'] == 'ready' and (classifier_prefix in c['classifier_id']):\n",
    "        classifier_id = c['classifier_id']\n",
    "\n",
    "\n",
    "if classifier_id is not None:\n",
    "    classifier = vr.get_classifier(classifier_id)\n",
    "    print '\\r\\nFound classifer:\\r\\n\\r\\n{}'.format(json.dumps(classifier, indent=2))\n",
    "else:\n",
    "    print 'No custom classifier available\\r\\n'\n",
    "    print(json.dumps(classifiers, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<br/>\n",
    "## Send the Images Archives to the Watson Visual Recognition Service for Training\n",
    "\n",
    "* https://www.ibm.com/watson/developercloud/doc/visual-recognition/customizing.html\n",
    "* https://www.ibm.com/watson/developercloud/visual-recognition/api/v3/\n",
    "* https://github.com/watson-developer-cloud/python-sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "squiggle = sorted(glob.glob('{}/classification_*_squiggle.zip'.format(zipfilefolder)))\n",
    "narrowband = sorted(glob.glob('{}/classification_*_narrowband.zip'.format(zipfilefolder)))\n",
    "narrowbanddrd = sorted(glob.glob('{}/classification_*_narrowbanddrd.zip'.format(zipfilefolder)))\n",
    "noise = sorted(glob.glob('{}/classification_*_noise.zip'.format(zipfilefolder)))\n",
    "#brightpixel = sorted(glob.glob('{}/classification_*_brightpixel.zip'.format(zipfilefolder)))\n",
    "#squarepulsednarrowband = sorted(glob.glob('{}/classification_*_squarepulsednarrowband.zip'.format(zipfilefolder)))\n",
    "#squigglesquarepulsednarrowband = sorted(glob.glob('{}/classification_*_squigglesquarepulsednarrowband.zip'.format(zipfilefolder)))\n",
    "\n",
    "sq = len(squiggle)\n",
    "nb = len(narrowband)\n",
    "nd = len(narrowbanddrd)\n",
    "ns = len(noise)\n",
    "#nbp = len(brightpixel)\n",
    "#nsp = len(squarepulsednarrowband)\n",
    "#nss = len(squigglesquarepulsednarrowband)\n",
    "\n",
    "## Possible todo here: Try using the 'noise' as a \"negative\" example when training Watson. See the Watson documentation.\n",
    "\n",
    "## for prototyping. \n",
    "num = 2\n",
    "#num = max(sq, nb, nd, ns)\n",
    "\n",
    "\n",
    "if classifier_id is None:\n",
    "    print 'Adding custom classifier ... this may take awhile'\n",
    "else:\n",
    "    print 'Updating custom classifier {} ... this may take awhile'.format(classifier_id)\n",
    "\n",
    "for i in range(num):\n",
    "    squiggle_p = open(squiggle[i], 'rb') if i < sq else None\n",
    "    narrowband_p = open(narrowband[i], 'rb') if i < nb else None\n",
    "    narrowbanddrd_p = open(narrowbanddrd[i], 'rb') if i < nd else None\n",
    "    noise_p = open(noise[i], 'rb') if i < ns else None\n",
    "    #brightpixel_p = open(brightpixel[i], 'rb') if i < nb else None\n",
    "    #squarepulsednarrowband_p = open(squarepulsednarrowband[i], 'rb') if i < nd else None\n",
    "    #squigglesquarepulsednarrowband_p = open(squigglesquarepulsednarrowband[i], 'rb') if i < ns else None\n",
    "    \n",
    "\n",
    "    if classifier_id is None:\n",
    "        print 'Creating new classifier. Batch {}'.format(i)\n",
    "        classifier = vr.create_classifier(\n",
    "            classifier_prefix,\n",
    "            squiggle_positive_examples = squiggle_p,\n",
    "            narrowband_positive_examples = narrowband_p,\n",
    "            narrowbanddrd_positive_examples = narrowbanddrd_p,\n",
    "            noise_positive_examples = noise_p\n",
    "            #brightpixel_positive_examples = brightpixel_p,\n",
    "            #squarepulsednarrowband_positive_examples = squarepulsednarrowband_p,\n",
    "            #squigglesquarepulsednarrowband_positive_examples = squigglesquarepulsednarrowband_p\n",
    "        )\n",
    "        \n",
    "        classifier_id = classifier['classifier_id']\n",
    "    else:\n",
    "        print 'Updating classifier. Batch {}'.format(i)\n",
    "        classifier = vr.update_classifier(\n",
    "            classifier_id,\n",
    "            squiggle_positive_examples = squiggle_p,\n",
    "            narrowband_positive_examples = narrowband_p,\n",
    "            narrowbanddrd_positive_examples = narrowbanddrd_p,\n",
    "            noise_positive_examples = noise_p\n",
    "            #brightpixel_positive_examples = brightpixel_p,\n",
    "            #squarepulsednarrowband_positive_examples = squarepulsednarrowband_p,\n",
    "            #squigglesquarepulsednarrowband_positive_examples = squigglesquarepulsednarrowband_p \n",
    "        )\n",
    "\n",
    "    if squiggle_p is not None:\n",
    "        squiggle_p.close()\n",
    "    if narrowband_p is not None:\n",
    "        narrowband_p.close()\n",
    "    if narrowbanddrd_p is not None:\n",
    "        narrowbanddrd_p.close()\n",
    "    if noise_p is not None:\n",
    "        noise_p.close()\n",
    "    #if brightpixel_p is not None:\n",
    "    #    brightpixel_p.close()\n",
    "    #if squarepulsednarrowband_p is not None:\n",
    "    #    squarepulsednarrowband_p.close()\n",
    "    #if squigglesquarepulsednarrowband_p is not None:\n",
    "    #    squigglesquarepulsednarrowband_p.close()\n",
    "\n",
    "    if classifier is not None:\n",
    "        print('Classifier: {}'.format(classifier_id))\n",
    "        status = classifier['status']\n",
    "        startTimer = timeit.default_timer()\n",
    "        print 'Working ...'\n",
    "        while status in ['training', 'retraining']:\n",
    "            # print('Status: {}'.format(status))\n",
    "            time.sleep(10)\n",
    "            classifier = vr.get_classifier(classifier_id)\n",
    "            status = classifier['status']\n",
    "        stopTimer = timeit.default_timer()\n",
    "        print '{} took {} minutes'.format('Training' if i == 0 else 'Retraining', int(stopTimer - startTimer) / 60)\n",
    "\n",
    "# print(json.dumps(vr.get_classifier(classifier_id), indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for image_archive_name in test_set:\n",
    "    image_count = 0\n",
    "    # count number of images in <image_archive_name>\n",
    "    with zipfile.ZipFile(image_archive_name,'r') as image_archive:\n",
    "        images = image_archive.namelist()\n",
    "        image_count = len(images)\n",
    "\n",
    "  \n",
    "    # bulk classify images in <image_archive_name>\n",
    "    with open(image_archive_name, 'rb') as images_file:\n",
    "        print 'Running test ({} images) for {}... this may take a while.'.format(image_count, image_archive_name)\n",
    "        classify_results = vr.classify(images_file=images_file, classifier_ids=[classifier_id], threshold=0.0)\n",
    "        # print(json.dumps(classify_results, indent=2))\n",
    "        # identify class from ZIP file name, e.g. testset_10_squiggle.zip\n",
    "        mo = re.match('^(.+)_(\\d+)_(.+)\\.zip$',image_archive_name.split('/')[-1])\n",
    "        classification = mo.group(3)\n",
    "        resdict = results_group_by_class[classification]\n",
    "        passed = 0\n",
    "\n",
    "        for classify_result in classify_results['images']:\n",
    "            pngfilename = classify_result['image'].split('/')[-1]\n",
    "            uuid = pngfilename.split('.')[0]\n",
    "\n",
    "            maxscore = 0\n",
    "            maxscoreclass = None\n",
    "\n",
    "            if \"error\" in classify_result:\n",
    "                # print error information\n",
    "                print classify_result\n",
    "                #add to failed list\n",
    "                failed_to_classify_uuid_list.append(uuid)                  \n",
    "            else:\n",
    "                classifiers_arr = classify_result['classifiers']\n",
    "                score_list = []\n",
    "                for classifier_result in classifiers_arr:\n",
    "                    for class_result in classifier_result['classes']:\n",
    "                        score_list.append((class_result['class'],class_result['score']))\n",
    "                        if class_result['score'] > maxscore:\n",
    "                            maxscore = class_result['score']\n",
    "                            maxscoreclass = class_result['class']\n",
    "\n",
    "                #sort alphabetically\n",
    "                score_list.sort(key = lambda x: x[0])\n",
    "                score_list = map(lambda x:x[1], score_list)\n",
    "\n",
    "                if maxscoreclass is None:\n",
    "                    print 'Failed: {} - Actual: {}, No classification returned'.format(pngfilename, classification)\n",
    "                    #print(json.dumps(classify_result, indent=2))\n",
    "                elif maxscoreclass != classification:\n",
    "                    print 'Failed: {} - Actual: {}, Watson Predicted: {} ({})'.format(pngfilename, classification, maxscoreclass, maxscore)\n",
    "                else:\n",
    "                    passed += 1\n",
    "                    print 'Passed: {} - Actual: {}, Watson Predicted: {} ({})'.format(pngfilename, classification, maxscoreclass, maxscore)\n",
    "\n",
    "                if maxscoreclass is not None:\n",
    "                    resdict['signal_classification'].append(classification)\n",
    "                    resdict['uuid'].append(uuid)\n",
    "                    resdict['watson_class'].append(maxscoreclass)\n",
    "                    resdict['watson_class_score'].append(maxscore)\n",
    "                    resdict['scores'].append(score_list)\n",
    "                else:\n",
    "                    #add to failed list\n",
    "                    failed_to_classify_uuid_list.append(uuid)\n",
    "        print 'Test Score: {}% ({} of {} Passed)'.format(int((float(passed) / image_count) * 100), passed, image_count)\n",
    "        print 'Tested {} images in {} minutes'.format(image_count, int(stopTimer - startTimer) / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "fwriter = csv.writer(sys.stdout, delimiter=',')\n",
    "print len(testresults)\n",
    "for items in testresults:\n",
    "    fwriter.writerow(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# testresults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# import pickle\n",
    "is istrainingset is True:\n",
    "    pickle.dump(results_group_by_class, open(mydatafolder + '/' + \"watson_results2.pickle\", \"w\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#TODO number results\n",
    "is istrainingset is True:\n",
    "    watson_results = pickle.load(open(mydatafolder + '/' + \"watson_results2.pickle\",\"r\"))\n",
    "\n",
    "    # reorganize the watson_results dictionary to extract\n",
    "    # a list of [true_class, [scores], estimated_class] and\n",
    "    # use these for measuring our model's performance\n",
    "\n",
    "    class_scores = []\n",
    "    for k in watson_results.keys():\n",
    "        class_scores += zip(watson_results[k]['uuid'], watson_results[k]['signal_classification'], watson_results[k]['scores'], watson_results[k]['watson_class'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class_scores[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(class_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import sklearn\n",
    "\n",
    "y_train = [x[1] for x in class_scores]\n",
    "y_pred = [x[3] for x in class_scores]\n",
    "y_prob = [x[2] for x in class_scores]\n",
    "#we normalize the Watson score values to 1 in order to use them in the log_loss calculation even though the Watson VR scores are not true class prediction probabilities\n",
    "y_prob = map(lambda x: (x, sum(x)), y_prob)\n",
    "y_prob = map(lambda x: [y / x[1] for y in x[0]], y_prob)\n",
    "\n",
    "print sklearn.metrics.classification_report(y_train,y_pred)\n",
    "print sklearn.metrics.confusion_matrix(y_train,y_pred)\n",
    "print(\"Classification accuracy: %0.6f\" % sklearn.metrics.accuracy_score(y_train,y_pred) )\n",
    "print(\"Log Loss: %0.6f\" % sklearn.metrics.log_loss(y_train,y_prob) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Generate CSV file for Scoreboard\n",
    "\n",
    "#### NOTE: This uses the PNG files created in the Step 3 notebook, which only contain the BASIC4 data set. The code challenge and hackathon will be based on the Primary Data Set which contains 7 signal classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "#TODO number scores\n",
    "my_output_results = mydatafolder + '/' + 'watson_scores2.csv'\n",
    "with open(my_output_results, 'w') as csvfile:\n",
    "    fwriter = csv.writer(csvfile, delimiter=',')\n",
    "    for row in class_scores:\n",
    "        fwriter.writerow([row[0]] + row[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#print out the first 10 lines just to show it makes sense\n",
    "\n",
    "!cat $mydatafolder/watson_scores2.csv\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2 with Spark 2.1",
   "language": "python",
   "name": "python2-spark21"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}